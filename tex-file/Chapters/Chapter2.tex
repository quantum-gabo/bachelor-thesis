%----------------------------------------------------------------------------------------

% Chapter 2

\chapter{Theoretical Background} % Main chapter title

\label{Chapter2} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 2. \emph{Theoretical Background}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
\section{Many Body Schrödinger Equation}
\label{section.schorödinger_equation}
In the realm of materials science, exploring particle behavior within a system inevitably involves navigating the intricate principles of quantum mechanics. This journey commences with a comprehensive dissection of the energy components governing interactions among various particles, notably electrons and nuclei. At its core, quantum mechanics introduces the dual nature of particle-wave duality, with wavefunctions serving as the foundational framework.

As we delve deeper into the quantum landscape, one fundamental interaction shaping particle behavior is the Coulomb interaction. This interaction arises from the electrostatic forces between charged particles(electrons or nuclei), playing a pivotal role in determining the dynamics of electrons and nuclei within a material system \supercite{Giustino2014,Sholl2009}.

The Coulomb interaction presents itself through three essential components: electron-electron, nucleus-nucleus, and electron-nuclei interactions. Mathematically, these interactions are expressed as follows:
\begin{itemize}
    \item Electron-Electron interactions: between electron pairs
    \begin{equation} \label{eq_1}
        \hat{V}_{ee} = \dfrac{1}{2}\sum_{i\neq j }^{N}\dfrac{e^{2}}{4\pi\epsilon_{0} }\dfrac{1}{|\mathbf{r_i}-\mathbf{r_j}|}
    \end{equation}
    \item Nuclei-Nuclei interactions: between nuclei pairs
    \begin{equation} \label{eq_2}
        \hat{V}_{nn} = \dfrac{1}{2}\sum_{I\neq J }^{M}\dfrac{e^{2}}{4\pi\epsilon_{0}}\dfrac{Z_I Z_J}{|\mathbf{R_I}-\mathbf{R_J}|}  
    \end{equation}
    \item Electron-Nuclei interaction:between electrons and nuclei 
    \begin{equation} \label{eq_3}
        \hat{V}_{en} = -\sum_{i,I }^{N,M}\dfrac{e^{2}}{4\pi\epsilon_{0}}\dfrac{Z_I}{|\mathbf{r_i}-\mathbf{R_I}|}  
    \end{equation}
\end{itemize}
Additionally, we need to consider the kinetic energy of both the N electrons and the M nuclei:

\begin{equation} \label{eq_4}
    \hat{K} = - \sum_{i=1}^{N} \dfrac{\hbar^{2}}{2m_e} \nabla_{i}^{2}-\sum_{I=1}^{M}\dfrac{\hbar^{2}}{2M_{I}}\nabla_{I}^{2} 
\end{equation}
As we aim to explore the ground states of interacting electron and nuclei particles, we must consider the time-independent Schrödinger equation, defined simply as:

\begin{equation} \label{eqn5}
	\hat{H} \psi(\mathbf{r})= E \psi (\mathbf{r})
\end{equation}

Here $\hat{H}$  is the hamiltonian operator, which includes both kinetic and potential energies, and $\psi(\mathbf{r})$ is the wavefunction that describes the system's properties. For many-body systems, the wavefunction $\mathbf{\Psi}$ describes the positions of all electrons $\left( \mathbf{r_1}, \mathbf{r_2}, \mathbf{r_3}, ...,  \mathbf{r_N} \right)$ and nuclei $\left( \mathbf{R_1}, \mathbf{R_2}, \mathbf{R_3}, ...,  \mathbf{R_M} \right)$. 

Expanding on equation \ref{eqn5}, we get:
\begin{equation} \label{eq_5}
    \left(\hat{K} + \hat{V}\right) \Psi = E_{tot} \Psi
\end{equation}
Combining \ref{eq_1},\ref{eq_2}, \ref{eq_3}, and \ref{eq_4}, we can describe the many-body Schrödinger equation for $N$ electrons and $M$ nuclei as:
\begin{equation} \label{eq_6}
\begin{split}
    \Biggl[-\sum_{i}\dfrac{\hbar^{2}}{2m_{e}}\nabla_{i}^{2} -\sum_{I} \dfrac{\hbar ^{2}}{M_I} \nabla_{I}^{2}+ \dfrac{1}{2}\sum_{i\neq j}\dfrac{e^{2}}{4\pi\epsilon_{0} }\dfrac{1}{|\mathbf{r_i}-\mathbf{r_j}|}+\\
    \dfrac{1}{2}\sum_{I\neq J}\dfrac{e^{2}}{4\pi\epsilon_{0}}\dfrac{Z_I Z_J}{|\mathbf{R_I}-\mathbf{R_J}|}  -\sum_{i,I}\dfrac{e^{2}}{4\pi\epsilon_{0}}\dfrac{Z_I}{|\mathbf{r_i}-\mathbf{R_I}|}\Biggr] \Psi = E_{tot} \Psi
\end{split}
\end{equation}

An issue related to equation \ref{eq_6} is its complexity in solving for many interacting particles. However, astonishing approximation methods have been studied over the last century, providing excellent accuracy to perform atomic simulations, which will be discussed in the next section.

\section{Adiabatic Approximation}
\label{section.adiabatic_approximation}
The \ref{eq_6} represents a first-principle approach to describing many-body interactions in quantum mechanics. In this framework, it's crucial to establish a consistent set of atomic units for simplification and computational efficiency. Let's define some commonly used
atomic units:
\begin{equation*}
\begin{split}
    \hbar&= 1.05457163 \times 10^{34} Js \\
    m_e  &= 9.10938291 \times 10^{-31} kg \\
    m_p  &= 1.67262164 \times 10^{-27} kg \\
    e    &= 1.60217649 \times 10^{-19} C \\
    \epsilon_{0} &= 8.85418782 \times 10^{-12} F/m
\end{split}
\end{equation*}

As we delve into the intricacies of kinetic energies within \ref{eq_6}, the Hartree energy $\left(E_{H} \right)$ emerges as a key player. Representing the total electrostatic interaction energy within a system of electrons and nuclei, excluding electron-electron interactions, the Hartree energy becomes particularly illuminating in the context of hydrogen atoms. In this scenario, characterized by a solitary electron and a single nucleus (proton), the Hartree energy aligns with the Coulomb energy of the electron-proton pair, and defined as 

\begin{equation}
    E_{Ha}=\dfrac{e^{2}}{4\pi\epsilon_{0}a_{0}}
\end{equation}

where $a_0 \simeq 0.529$ \AA \ and based on its  angular momentum:

\begin{equation}
    m_{e}v a_{0} = \hbar  
\end{equation}

Taking into account that inside the orbit of a hydrogen atom, the attraction of the electron to the nucleus is given by:

\begin{equation}
    m_e \dfrac{e^{2}}{a_{0}}= \dfrac{e^{2}}{4 \pi \epsilon_{0} a_{0}^{2}}
\end{equation}

We arrive at two important relations:
\begin{equation}
    \dfrac{e^{2}}{4\pi\epsilon_{0}a_{0}}=\dfrac{\hbar^{2}}{m_{e} a_{0}^{2}}
\end{equation}
and
\begin{equation}
    \dfrac{1}{2}m_{e}v^{2} = \dfrac{1}{2} E_{Ha}
\end{equation}

Then, by dividing each term of \ref{eq_6} by $E_{Ha}$, then we get:
\begin{equation} \label{eq_12}
\begin{split}
    \Biggl[-\sum_{i} \dfrac{1}{2}a_{0}^{2}\nabla_{i}^{2} -\sum_{I} \dfrac{1}{2\bigl(M_{I}/m_e\bigr)}a_{0}^{2}\nabla_{I}^{2} + \dfrac{1}{2}\sum_{i\neq j}\dfrac{a_{0}}{|\mathbf{r_i}-\mathbf{r_j}|} \\
    +\dfrac{1}{2} \sum_{I\neq J}Z_{I}Z_{J} \dfrac{a_{0}}{|\mathbf{R_I}-\mathbf{R_J}|}-\sum_{i,I}Z_{I}\dfrac{a_{0}}{|\mathbf{r_i}-\mathbf{R_I}|} \Biggr] \Psi = \dfrac{E_{tot}}{E_{Ha}} \Psi
\end{split}
\end{equation}

As we treat with Hartree atomic units, then the four constants that appear in \ref{eq_12} are set to 1. Thus,

\begin{equation} \label{eq_13}
\begin{split}
    \Biggl[-\sum_{i}\dfrac{\nabla_{i}^{2}}{2} -\sum_{I}\dfrac{\nabla_{I}^{2}}{2M_I} -\sum_{i,I} \dfrac{Z_I}{|\mathbf{r_i}-\mathbf{R_I}|}+\dfrac{1}{2}\sum_{i\neq j}\dfrac{1}{|\mathbf{r_i}-\mathbf{r_j}|}+ \\
    \dfrac{1}{2}\sum_{I\neq J}\dfrac{Z_{I}Z_{J}}{|\mathbf{R_I}-\mathbf{R_J}|} \Biggr]\Psi = E_{tot} \Psi
\end{split}
\end{equation}

Now, based on the fact that the mass of nuclei is around 2000 times greater than the electron mass, implying that the kinetic energy of nuclei can be neglected; and also since the positions $\mathbf{R}$ are shifted by a constant amount, we have:

\begin{equation}
\sum_{I}\dfrac{\nabla_{I}^{2}}{2M_I} = 0
\quad \mbox{and} \quad
E=E_{tot}-\dfrac{1}{2}\sum_{I\neq J}\dfrac{Z_{I}Z_{J}}{|\mathbf{R_I}-\mathbf{R_J}|}
\end{equation}


And recognize that the term 
\begin{equation}
V_{n}(\mathbf{r})= -\sum_{i,I} \dfrac{Z_I}{|\mathbf{r_i}-\mathbf{R_I}|}
\end{equation}

is accounting for the Coulomb potential of the nuclei experienced by the electrons. Then rewritten Eq. \ref{eq_13}:

\begin{equation} \label{eq_15}
	\begin{split}
		\Biggl[-\sum_{i}\dfrac{\nabla_{i}^{2}}{2} +\sum_{i}V_{n}(\mathbf{r_i})+\dfrac{1}{2}\sum_{i\neq j} \dfrac{1}{|\mathbf{r_i}-\mathbf{r_{j}}|}  \Biggr]\Psi =E \Psi
	\end{split}
\end{equation}

In order to know the equilibrium structure of a any system, we can treat the nuclei as fixed and thus we can approach the total wavefuction $\Psi$ by separation of variables, splitting it into a wavefunction for electrons $\Psi_R$ (that depends on the $\mathbf{R}$ nuclei positions) and the other one for nuclei($\chi$):

\begin{equation} \label{eq_16}
    \Psi \left(r_1,..., r_N, R_1, ..., R_M \right) = \Psi_R \left(r_1, ..., r_N\right) \chi\left(R_1, ..., R_M \right)
\end{equation}

So, rewritten Eq. \ref{eq_15} in terms of $\mathbf{R}$ nuclei positions 
\begin{equation} \label{eq_17}
    \begin{split}
		\Biggl[-\sum_{i}\dfrac{\nabla_{i}^{2}}{2} +\sum_{i}V_{n}(\mathbf{r}_{i};\mathbf{R})+\dfrac{1}{2}\sum_{i\neq j} \dfrac{1}{|\mathbf{r_i}-\mathbf{r_{j}}|}  \Biggr]\Psi_{\mathbf{R}} =E_{\mathbf{R}} \Psi_{\mathbf{R}}
	\end{split}
\end{equation}


Here $E_{R}=E\left(R_{1}, ..., R_{M} \right)$ represents the total electronic energy as a function of all nuclei positions, and $V_{n}$ represents the Coulomb potential of the nuclei experienced by the electrons. It is  also important to note that by using Eqs. \ref{eq_16} and \ref{eq_17} into equation \ref{eq_13}, and then of applying normalization condition we obtain a equation describing solely the behavior of nuclei:
\begin{equation} \label{eq_18a}
    \Biggl[-\sum_{I}\dfrac{\nabla_{I}^{2}}{2M_{I}}+\dfrac{1}{2}\sum_{I\neq J}\dfrac{Z_I Z_J}{|\mathbf{R}_I-\mathbf{R}_J|}+E\left(\mathbf{R}_1, ..., \mathbf{R}_M \right) \Biggr]\chi = E_{tot}\chi
\end{equation}

The separation of the total wavefunction into the components described by equations \ref{eq_17} and \ref{eq_18a} is significant because it allows us to understand how the system behaves when there are changes in the positions of the nuclei. When the nuclei undergo small deviations from their initial positions to their final positions relative to the ground state, the electrons continue to occupy their lowest energy states. This phenomenon is known as adiabatic evolution, where the electron configuration adjusts smoothly to changes in the nuclear positions while staying in its ground state.

\section{Hartree-Fock Theory}

\subsection{Pauli's exclusion principle}
At the heart of the Hartree-Fock theory lies the Pauli exclusion principle, which states that no two fermions (particles with half-integer spin, such as electrons) can occupy the same quantum state simultaneously. This principle plays a crucial role in understanding the behavior of electrons in atoms and molecules, as it imposes constraints on the possible configurations of electron states.

To account for the Pauli exclusion principle, we introduce the concept of a Slater determinant. A Slater determinant is a determinant constructed from a set of orthonormal single-electron wavefunctions $\phi_i(\mathbf{r})$. For a system of N interacting electrons, the Slater determinant is constructed as follows:
\begin{equation} \label{eq_18}
\Psi(\mathbf{r_1}, ...,\mathbf{r_N})=   \dfrac{1}{\sqrt{N!}}
    \begin{vmatrix}
    \phi_1(r_1) & \phi_1(r_2) & \cdots & \phi_1(r_N) \\
    \vdots & \vdots & \ddots & \vdots \\
    \phi_N(r_1) & \phi_N(r_2) & \cdots & \phi_N(r_N)
    \end{vmatrix}
\end{equation}

\subsection{Mean Field Approximation}
Based on \ref{eq_16} we know that first two terms provide a way to account for the single-electron Hamiltonian, this is:
\begin{equation} \label{eq_19}
    \hat{H}_0 = -\sum_{i}\dfrac{\nabla_{i}^{2}}{2} +\sum_{i}V_{n}(\mathbf{r_i})
\end{equation}
This Hamiltonian allows us to define Schrodinger equation based only of independent electrons:

\begin{equation} \label{eq_2.23a}
	\sum_{i} \hat{H}_{0} (\mathbf{r}_i) \Psi = E \Psi
\end{equation}
where 

\begin{equation}
	\Psi \left( \mathbf{r}_1, \mathbf{r}_2, ..., \mathbf{r}_N \right) = \phi_{1}(\mathbf{r}_1) ... \phi_N(\mathbf{r}_N) 
\end{equation}
Now in order to guarantee the Pauli's exclusion principle, i.e $\Psi(\mathbf{r}_2, \mathbf{r}_1) = - \Psi(\mathbf{r}_1, \mathbf{r}_2)$; we can use the definition of Slater determinant given by Eq. \ref{eq_18}. Let's consider the case for $N=$2 electrons:

\begin{equation} \label{eq_2.25a}
	\Psi(\mathbf{r}_1, \mathbf{r}_2) = \dfrac{1}{\sqrt{2}} \left[\phi_{1}(\mathbf{r}_1)\phi_{2}(\mathbf{r}_2) - [\phi_{1}(\mathbf{r}_2)\phi_{2}(\mathbf{r}_1) \right]
\end{equation}

Then applying the normalization condition to that wavefunction, we arrive to the electron charge density $n(\mathbf{r})$:

\begin{equation}
	n (\mathbf{r}) = |\phi_{1}(\mathbf{r})|^{2} + |\phi_{2}(\mathbf{r})|^{2}
\end{equation}

And as we know from classical electrostatic (from Poisson's equation: $\nabla^{2} V_{H}(\mathbf{r}) = -4 \pi n(\mathbf{r})$) an electronic charge will generate a electrostatic potential as follows:

\begin{equation}
	V_{H} (\mathbf{r}) = \int d \mathbf{r}' \dfrac{n(\mathbf{r}')}{|\mathbf{r}-\mathbf{r}'|}
\end{equation}

This allows us to account for an extra term in the Schrodinger equation for each indepedent electron (within Eq. \ref{eq_2.23a}):


\begin{equation}
	\left[ - \dfrac{\nabla^{2}}{2} + V_{n} (\mathbf{r}) + V_{H}(\mathbf{r})\right] \phi_{i} (\mathbf{r}) = \varepsilon_{i} \phi_{i} (\mathbf{r})
\end{equation}

These equations must be solved numerically and simultaneously among the Poisson's equation and the total electronic charge density ($n(\mathbf{r})= \sum_{i} |\phi_{i} (\mathbf{r})|^{2}$).

\subsection{Hartree-Fock equations}

As we see in the last subsection we can neglect the Coulomb repulsion of electrons. However that interaction as  currently we know is not too strong and we can still search for the  solution of single-particle wavefunctions, $\phi_i(\mathbf{r})$, in the form of a Slater determinant. Those solutions can be obtained using 'variational principle'.

First at all, lets consider the case for $N=2$ electrons as it was described in the Eq. \ref{eq_2.25a} and its lowest energy (in its Dirac notation):

\begin{equation}\label{eq_2.29a}
	E = \langle \Psi | \hat{H}| \Psi\rangle
\end{equation}

Then, the Hamiltronian for this system can be expanded using Eq. \ref{eq_2.23a}:
\begin{equation} \label{eq_2.30a}
\left[\hat{H}_{0}(\mathbf{r}_1)+\hat{H}_{0}(\mathbf{r}_2) + \dfrac{1}{|\mathbf{r}_1 -\mathbf{r}_2|} \right] \Psi = E \Psi	
\end{equation}

Then combining Eqs. \ref{eq_2.25a}, \ref{eq_2.29a}, and \ref{eq_2.30a} and applying normalized and ortogonalized conditions ($\langle \psi_1 | \psi_1 \rangle = \langle \psi_2 | \psi_2 \rangle = 1$, and $\langle \psi_1 | \psi_2 \rangle = \langle \psi_2 | \psi_1 \rangle = 0$ ) after several algebraic manipulations:

\begin{align*}
	E & = \int d \mathbf{r} \psi_{1}^{*} \hat{H}_{0}(\mathbf{r})\psi_{1}(\mathbf{r}) + \int d \mathbf{r} \psi_{2}^{*} (\mathbf{r}) \hat{H}_{0}(\mathbf{r}) \psi_2(\mathbf{r}) \\
	& + \int d \mathbf{r}_{1} d \mathbf{r}_{2} \dfrac{\psi_{1}^{*}(\mathbf{r}_{1})\psi_{2}^{*}(\mathbf{r}_{2})\psi_{1}(\mathbf{r}_{1})\psi_{2}(\mathbf{r}_{2})}{|\mathbf{r}_1-\mathbf{r}_2|} -  \int d \mathbf{r}_{1} d \mathbf{r}_{2} \dfrac{\psi_{1}^{*}(\mathbf{r}_{1})\psi_{2}^{*}(\mathbf{r}_{2})\psi_{1}(\mathbf{r}_{2})\psi_{2}(\mathbf{r}_{1})}{|\mathbf{r}_1-\mathbf{r}_2|} 
\end{align*}
The last equations shows us the energy $E$ is a functional of of $\psi_1$ and $\psi_2$. Then, we have to find those wavefunctions in order to minimize the functional. This is:
\begin{equation}
	\dfrac{\delta E}{\delta \psi_{1}} =0 \ , \dfrac{\delta E}{\delta \psi_{2}} = 0
\end{equation}
This minimization procedure would be treated better if we use Lagrange multipliers:
\begin{equation}
	L\left[\psi_{1}, \psi_{2}, \lambda_{11}, ..., \lambda_{22} \right] = E[\psi_{1}, \psi_{2}] - \sum_{i,j} \lambda_{ij} \left[\langle \psi_{i} | \psi_{j}\rangle  - \delta_{ij}\right]
\end{equation}
Then, the minimization problem becomes:
\begin{equation}
	\dfrac{\delta L}{\delta \psi_{i}} = 0 \ , i=1, 2, \quad \dfrac{\delta L}{\delta \lambda_{ij}} = 0 \ , i,j=1, 2
\end{equation}

After several algebraic manipulations and using the transformation:

\begin{equation}
	\phi_i = \sum_{j} S_{ij} \psi_{j}
\end{equation}

we get the so-called Hartree-Fock equations(generalized from the case $N=2$ electrons):

\begin{equation}
	\left[- \dfrac{\nabla^{2}}{2} + V_{n}(\mathbf{r}) + V_{H} (\mathbf{r}) \right] \phi_{i} (\mathbf{r}) + \int d \mathbf{r}' V_{X}(\mathbf{r},\mathbf{r}') \phi_{i} (\mathbf{r}') = \varepsilon_{i} \phi_{i} (\mathbf{r}) \ ,
\end{equation}
\begin{equation}
	n(\mathbf{r}) = \sum_{i} |\phi_{i}(\mathbf{r})|^{2} \ ,
\end{equation}
\begin{equation}
	\nabla^{2} V_{H} (\mathbf{r}) = -4 \pi n (\mathbf{r}) \ .
\end{equation} 


The importance of this equation lies in its ability to offer an accurate solution for the ground state based on a single-particle using the variational principle. As electrons inherently repel each other, the Hartree-Fock equations introduce an electron correlation, effectively minimizing the disparity between the calculated solution and the exact solution of the system.
\section{Density Functional Theory}
\label{section.DFT}
\subsection{Hohenberg-Kohn Theorem}
\label{subsection.HohenberKohn}
Based on \ref{eq_16} we can note that the left hand side represents the Hamiltonian of a many-electron system. This Hamiltonian encapsulates various energy contributions, such as kinetic energy, nuclear potential energy, and electron-electron repulsion. The Hohenberg-Kohn theorem plays a fundamental role in understanding the implications of this equation. To grasp its significance, let's start with the concept of the Hamiltonian's expectation value, denoted by
$E$:
\begin{equation} \label{eq_32}
    E = \mel{\Psi}{\hat{H}}{\Psi}= \int d\mathbf{r}_1 \cdots d\mathbf{r}_N \Psi^{*}(\mathbf{r}_1, \cdots \mathbf{r}_N) \hat{H} \Psi(\mathbf{r}_1, \cdots \mathbf{r}_N)
\end{equation}
Now, here's where it gets interesting. The Hohenberg-Kohn theorem highlights a critical insight: If $E$ represents the lowest energy state of the system, then 
$E$ is uniquely determined by the electron density $n$:

\begin{equation} \label{eq_33}
    E=F[n]
\end{equation}

Why is this equation so powerful? Well, consider this: the wave function $\Psi(\mathbf{r}_1, \cdots \mathbf{r}_N)$ describes a system with $N$ electrons, each moving in three-dimensional space. That's a whopping $3N$ unknowns to solve for! It's practically impossible to tackle directly. But the Hohenberg-Kohn theorem simplifies everything by asserting that the ground state energy depends solely on the electron density, which is a function of just three variables. This remarkable theorem is built upon three logical premises:

\begin{enumerate}
    \item The electron density uniquely determines the external potential felt by the nuclei.
    \item This external potential determines the wave function describing the behavior of the many-electron system.
    \item Finally, the wave function uniquely determines the total energy of the system,meaning that the ground state is non-degenerate.
\end{enumerate}
The amalgamation of these premises crystallizes into the central theorem, encapsulated in Equation \ref{eq_33}. This succinctly encapsulates the profound implications of the Hohenberg-Kohn theorem\supercite{Hohenberg1964}, which can be distilled into two succinct theorems \supercite{Dresselhaus2018}:
\begin{theorem}{}{}  \label{HK1}
When a system of N interacting electrons is subjected to an external potential $V_{ext}$, this potential is solely dependent of the electron density $n$ of the ground state. 
\end{theorem}
\begin{theorem}{}{} \label{HK2}
Let $E[n]$ denote the functional representing the energy relative to the electronic density for a given $V_{ext}$. Then, this functional attains its global minimum corresponding to the ground state.
\end{theorem}

Let's proceed to prove both theorems. As indicated by equation \ref{eq_16}, the Hamiltonian for a many-electron system is defined as:

\begin{equation} \label{eq_34}
\hat{H}=-\sum_{i}\dfrac{\nabla_{i}^{2}}{2} +\sum_{i}V_{n}(\mathbf{r_i})+\dfrac{1}{2}\sum_{i\neq j} \dfrac{1}{|\mathbf{r_i}-\mathbf{r_{j}}|}=\hat{T}+ V_{ext}+\hat{W}
\end{equation}
where $\hat{T}$ represents the kinetic energy, $V_{ext}$ denotes the external potential, and $\hat{W}$ accounts for the Coulomb energy. The expectation value of that Hamiltonian gives us:
\begin{equation} \label{eq_35}
\begin{aligned}
    E&= \mel{\Psi}{\hat{H}}{\Psi}=\mel{\Psi}{V_{ext}}{\Psi}+\mel{\Psi}{\hat{T}+\hat{W}}{\Psi} \\
    E&=\mel{\Psi}{\sum_{i}V_{n}(\mathbf{r})}{\Psi} +\mel{\Psi}{\hat{T}+\hat{W}}{\Psi} \\
    E&=\int V_n (\mathbf{r})n(\mathbf{r})d  \mathbf{r}+\mel{\Psi}{\hat{T}+\hat{W}}{\Psi}
\end{aligned}
\end{equation}
Now, let's make the assumption in line with  \ref{HK1}, that there are two distinct  ground states capable of yielding the same particle density.
\begin{equation} \label{eq_36}
\begin{aligned}
    E_0 &= \mel{\Psi_0}{\hat{H}}{\Psi_0}<\mel{\Psi_{0}^{'}}{\hat{H'}}{\Psi_{0}^{'}}=\mel{\Psi_{0}^{'}}{\hat{H'}-\sum_{i}V'_{n}(\mathbf{r})+\sum_{i}V_{n}(\mathbf{r})}{\Psi_{0}^{'}} \\
    E_0 &< E'_0 + \mel{\Psi_{0}^{'}}{\sum_{i}[V_{n}(\mathbf{r_i})-V'_n(\mathbf{r_i})]}{\Psi_{0}^{'}} \\
\end{aligned}    
\end{equation}
This results in:
\begin{equation} \label{eq_37}
	     E_0 < E'_0 + \int [V_{n}(\mathbf{r})-V'_n(\mathbf{r})] n(\mathbf{r})d \mathbf{r}
\end{equation}
Using a similar procedure, we obtain the eigenvalue $E'_0$:
\begin{equation} \label{eq_38}
	     E_0 < E'_0 - \int [V_{n}(\mathbf{r})-V'_n(\mathbf{r})] n(\mathbf{r})d \mathbf{r}
\end{equation}
Adding Equations \ref{eq_37} and \ref{eq_38}, we arrive at:
\begin{equation} \label{eq_39}
	E_0 + E'_0 < E_0 + E'_0 
\end{equation}
This contradiction disproves our initial assumption. Thus, it is evident that the ground state is dependent on the electronic density. 
\subsection{Kohn-Sham Method}
\label{subsection.Kohn_Sham}
The HK theorem facilitates a reduction in the computational cost when dealing with a system comprising N interacting electrons compared to the Hartree Fock Theory. We acknowledge the existence of the functional  $ E = F[n]$, but without knowledge of its form. Consequently, Kohn and Sham proposed a procedure, supported by refs.\supercite{Giustino2014,Scheffler2017,Lee2011}.

This functional) is expressed  as shown in equation \ref{eq_35}:

\begin{equation} \label{eq_44}
\begin{aligned}
	    F[n]&=\int V_n (\mathbf{r})n(\mathbf{r})d \mathbf{r}+\mel{\Psi[n]}{\hat{T}+\hat{W}}{\Psi[n]} 
\end{aligned}
\end{equation}

The last two terms are the kinetic energy and the Coulomb repulsion of electrons and in comparison with the fist term their density dependence is not explicit. In this context, Kohn and Show\supercite{Kohn1965} introduced an extra term $E_{xc}[n]$  to account for this discrepancy. Therefore rewritten \ref{eq_44}:
\begin{equation} \label{eq_45}
	E=\int V_n (\mathbf{r})n(\mathbf{r})d \mathbf{r}-\sum_{i} \int  \phi_{i}^{*}(\mathbf{r})\dfrac{\nabla^{2}}{2} \phi_{i}(\mathbf{r})d \mathbf{r} + \dfrac{1}{2} \iint \dfrac{n(\mathbf{r})n(\mathbf{r'})}{|\mathbf{r}-\mathbf{r'}|} d \mathbf{r} d \mathbf{r}' +E_{xc}[n]
\end{equation}

Then, employing the variational principle of the Hohenberg-Kohn theory -orthonormal constraint- that is analogous to the method employed by the Hartree-Fock. So, we iteratively construct a set of wave functions $\phi_i(\mathbf{r})$ through a self-consistent procedure, leading to the Kohn-Sham equations:
\begin{equation} \label{eq_46}
	\Biggl[-\dfrac{1}{2}+ V_n(\mathbf{r})+ V_H(\mathbf{r})+V_{xc}(\mathbf{r}) \Biggr]\phi_i(\mathbf{r})= \varepsilon_i \phi_i (\mathbf{r})
\end{equation}
Here $V_n(\mathbf{r})$ is the Hartree potential, $V_H (\mathbf{r})$  is the external potential, and $V_{xc}(\mathbf{r})$ is the exchange and correlation potential, defined as:
\begin{equation} \label{eq_47}
	V_{xc} = \dfrac{\delta E_{xc}[n]}{\delta n} \Biggr|_{n(\mathbf{r
		})}
\end{equation}
Our task now centers on crafting precise approximations for $E_{xc}[n]$.
\subsection{Exchange-Correlation Functionals}
\label{subsection.xc_functionals}
\subsubsection{Local Density Approximation}
\label{subsubsection.LDA}
To accurately describe the electronic properties of a system, various methods have been developed to approximate the exchange-correlation functional described in Eq. \eqref{eq_46}. One of the simplest and most commonly used approximations is the Local Density Approximation \supercite{CeperleyAlder1980, 
PerdewZunger1981}(LDA). This method approximates the electron density of an inhomogeneous system by dividing it into several regions of volume $d\mathbf{r}$, treating each of these regions as a homogeneous electron gas (HEG) within a total volume \( V \) and taking into account the Coulomb repulsion between electrons\supercite{Giustino2014}.


\begin{equation}
	E_{xc} ^{LDA}= \int d \mathbf{r} n (\mathbf{r}) \epsilon_{xc}^{HEG}\left( n (\mathbf{r})\right)
\end{equation}
where $\epsilon_{xc}^{HEG}$ represents the exchange-correlation energy density.

To improve the description of the exchange-correlation energy functional, it is useful to separate the exchange part from the correlation part \supercite{Morin2013}:

\begin{equation}
	E_{xc}^{LDA}[n] = E_{x}^{HEG}[n] + E_{c}^{HEG}[n]
\end{equation}

The exchange energy density  contribution is given by:

\begin{equation}
	\epsilon_{x}^{HEG}(n) = -\dfrac{3}{4} \left( \dfrac{3}{\pi} n \right)^{1/3} 
\end{equation}

The correlation energy  denisty was obtained using stochastic numerical methods and subsequently parametrized \supercite{CeperleyAlder1980,PerdewZunger1981}. The correlation energy \( E_c \) is expressed as:

\begin{equation}
	\epsilon_{c}^{HEG}(r_s (n)) = 
	\begin{cases} 
		A\ln r_s +B + C r_s \ln r_s  + D r_s & \text{if } r_s < 1, \\
		\frac{\gamma}{1 + \beta_{1} \sqrt{r_s} + \beta_{2} r_s} & \text{if } r_s \geq 1.
	\end{cases}
\end{equation}

where $A=0.0311, B=-0.048, C=0.002, D=-0.0116, \gamma = -0.1423, \beta_{1}=1.0529, \beta_{2}=0.334$. Here, \( r_s \) the Wigner-Seitz radius,  is a dimensionless parameter representing the average inter-electron distance; i.e :

\begin{equation}
	r_s = \left( \dfrac{3}{4 \pi n} \right)^{1/3}
\end{equation}

By utilizing the LDA, researchers can make reasonable approximations for the exchange-correlation functional in systems where the electron density varies slowly. This method forms the foundation for more sophisticated approximations and has been instrumental in the advancement of density functional theory (DFT) calculations in material science and condensed matter physics.
\subsubsection{Local Spin Density Approximation}
To study magnetic systems, such as magnetic monolayers, it is crucial to account for spin polarization, as this is essential for capturing the system’s magnetic properties. Unlike the LDA, which treats the electron density as spin-independent, many magnetic systems require a treatment that explicitly includes spin polarization. This involves considering separate spin-up (\(n_{\uparrow}\)) and spin-down (\(n_{\downarrow}\)) densities, which is essential for accurately describing the magnetic characteristics of the system.


In the Local Spin Density Approximation (LSDA), the exchange-correlation energy functional \(E_{xc}^{LSDA}\) is modified to account for spin polarization. It is given by:

\begin{flalign}
	E_{xc}^{LSDA} \left[n_{\uparrow}, n_{\downarrow} \right] &= \int d \mathbf{r} n(\mathbf{r}) \, \epsilon_{xc}^{HEG} (n_{\uparrow}(\mathbf{r}), n_{\downarrow}(\mathbf{r}))  \\
 & =  \int d \mathbf{r} n(\mathbf{r}) \left[ \epsilon_{x}^{HEG} (n_{\uparrow}(\mathbf{r}), n_{\downarrow}(\mathbf{r})) + \epsilon_{c}^{HEG} (n_{\uparrow}(\mathbf{r}), n_{\downarrow}(\mathbf{r}))\right] \nonumber
\end{flalign}

Here, \(\epsilon_{xc}^{HEG}\) represents the exchange-correlation energy per particle for a homogeneous electron gas, which depends on the spin-up and spin-down densities.

The exchange energy contribution \(E_{x}^{LSDA}\) is calculated using:

\begin{equation}
	E_{x}^{LSDA} \left[ n_{\uparrow}, n_{\downarrow} \right] = \dfrac{1}{2} \left[ E_{x}^{LDA}[2n_{\uparrow}] + E_{x}^{LDA}[2n_{\downarrow}] \right]
\end{equation}

The exchange energy per electron \(\epsilon_{x}^{HEG}(n, \zeta)\) is then expressed as:

\begin{equation}
	\epsilon_{x}^{HEG}(n, \zeta) = \epsilon_{x}^{HEG} (n, \zeta = 0) + \left[ \epsilon_{x}^{HEG} (n, \zeta = 1) - \epsilon_{x}^{HEG}(n, \zeta=0) \right] f(\zeta)
\end{equation}

where \(\zeta\) is the spin polarization parameter, defined by:

\begin{equation}
	\zeta = \frac{n_{\uparrow} - n_{\downarrow}}{n_{\uparrow} + n_{\downarrow}}
\end{equation}

and \(f(\zeta)\) is a factor accounting for spin polarization:

\begin{equation}
	f(\zeta) = \frac{(1+\zeta)^{4/3} + (1-\zeta)^{4/3} - 2}{2(2^{1/3} - 1)}
\end{equation}

The correlation energy can be computed numerically using the Random Phase Approximation (RPA) and then parametrized as described in the literature \supercite{VonBarth1972, Vosko1980}.

To assess the effectiveness of LSDA, it is helpful to define the exchange-correlation hole density as a function of electron distances, \(\overline{n}_{xc}^{HEG}(n_{\uparrow}, n_{\downarrow}; u)\). The average hole density for LSDA is:

\begin{equation}
	\langle \overline{n}_{xc}^{LSDA}(u) \rangle = \dfrac{1}{N} \int d \mathbf{r} \, n(\mathbf{r}) \, \overline{n}_{xc}^{HEG} \left( n_{\uparrow}(\mathbf{r}), n_{\downarrow}(\mathbf{r}) \right)
\end{equation}

Evaluating this average density at the same point, \(\langle \overline{n}_{xc}(u=0) \rangle\), reveals why \(E_{xc}^{LSDA}\) performs well in a local regime, predicting suitable the total  $E_{xc}^{LSDA}$. However, it also shows that the LSDA does not adequately capture the correlation hole \(\overline{n}_c^{LSDA}(u)\). Implyieng an undertimation and overstimation of exchange and correlation energies, respectively.
\subsubsection{Generalized Gradient Approximation}
\label{subsubsection.GGA}
To address the limitations of the Local Spin Density Approximation (LSDA), the Generalized Gradient Approximation (GGA) represents a significant advancement in density functional theory (DFT). The GGA enhances the accuracy of DFT calculations by incorporating not only the electron density \(n(\mathbf{r})\) but also its gradient \(|\nabla n(\mathbf{r})|\) in the exchange-correlation energy functional. This approach allows GGA to better handle spin electron densities.

The exchange-correlation energy within the GGA framework is expressed as:

\begin{equation}
	E_{xc}^{GGA} = \int d \mathbf{r} \, n (\mathbf{r}) \, \epsilon_{xc}^{HEG} (n(\mathbf{r})) \, F_{xc} \left[n_\uparrow(\mathbf{r}), n_\downarrow(\mathbf{r}), \nabla n_\uparrow(\mathbf{r}), \nabla n_\downarrow(\mathbf{r}) \right]
\end{equation}

Here, \(F_{xc}\) represents an enhancement factor that depends on both the density and its gradient, providing a more accurate description of the exchange-correlation effects.

Among various GGA functionals, the Perdew-Burke-Ernzerhof (PBE) functional is one of the most prominent and widely utilized. The exchange energy within the PBE functional is given by:

\begin{equation}
	E_{x}^{PBE} = \int d \mathbf{r} \, \epsilon_{x}^{HEG} (n) \left[1+ \kappa - \dfrac{\kappa}{1+ \beta \pi^{2}s^{2}/3 \kappa}\right]
\end{equation}

where \(s(\mathbf{r})\) is defined as:

\begin{equation}
	s(\mathbf{r}) = \dfrac{|\nabla n (\mathbf{r})|}{2 n (\mathbf{r}) k_{F}(\mathbf{r})}
\end{equation}

The correlation energy in the PBE functional is expressed as:

\begin{equation}
	E_{c}^{PBE} = \int d \mathbf{r} \left[\epsilon_{c}^{HEG} + n c_0 \phi^{3} \ln \left\{1+ \dfrac{(1+At^2)\beta t^{2}/c_0}{1+A t^{2}+A^{2}t^{4}}\right\}\right]
\end{equation}

where \(t(\mathbf{r})\) is given by:

\begin{equation}
	t(\mathbf{r}) = \dfrac{|\nabla n (\mathbf{r})|}{2 n (\mathbf{r}) k_{s}(\mathbf{r})} \quad \text{and} \quad k_s = \sqrt{\frac{4 k_F}{\pi}}
\end{equation}

In general, the PBE functional tends to overestimate equilibrium lattice constants by approximately 1\%, which contrasts with the LDA's tendency to underestimate these values by a similar margin. This discrepancy is significant in ab initio calculations, as it affects various properties such as phonons, magnetic moments, and band gaps. Perdew has noted that GGA functionals, including PBE, face a trade-off: while they may improve the accuracy of total energy calculations, they can worsen bond lengths. 

To address this issue, the PBEsol functional has been proposed. The PBEsol functional aims to reduce the dependence on gradient density to achieve more accurate lattice parameters compared to PBE. However, it is worth noting that using PBEsol can lead to less accurate total energy predictions. Thus, while GGA functionals represent a substantial improvement over LSDA, they come with their own set of trade-offs that need to be carefully considered depending on the specific requirements of the computational study.


\subsubsection{Hybrid functionals}

The limitations observed in PBE and PBEsol functionals lead to the exploration of hybrid functionals, which aim to combine the advantages of different approaches to enhance accuracy. Hybrid functionals incorporate a portion of exact exchange from Hartree-Fock theory and other part comes splitting exchange-correlation potential into its exchange and correlation parts.
\begin{equation}
	\left(-\dfrac{1}{2} \nabla^{2} +V_{n} +V_{H}[n](\mathbf{r})+(1- \alpha)V_{x}[n](\mathbf{r})+V_{c}[n](\mathbf{r})  \right)\psi_{i}(\mathbf{r}) + \int \alpha V_{x}^{HF}(\mathbf{r},\mathbf{r}') \psi_{i}(\mathbf{r}') d \mathbf{r}' = \varepsilon_{i} \psi_{i} (\mathbf{r})
\end{equation}

where $0<\alpha<1$. There are some common recipes, such as 'PBE0',that accounts for a mixing of Hartree-Fock exact exchange and a contribution of PBE exchange-correlations parts.

\begin{equation}
	E_{xc}^{PBE0} = \dfrac{1}{4}E_{x}^{HF} + \dfrac{3}{4} E_{x}^{PBE}+E_{c}^{PBE}
\end{equation}


Another common recipe is the HSE06 (Heyd-Scuseria-Ernzerhof 2006) functional, which is expressed as:

\begin{equation}
	E_{xc}^{HSE06} = \dfrac{1}{4}E_{x}^{HF,SR}(\omega) + \dfrac{3}{4} E_{x}^{PBE,SR}(\omega) +E_{x}^{PBE,LR}+E_{c}^{PBE}
\end{equation}

where $\omega$ controls the short and long-range separation and depends on the decomposition of Coulomb kernel:
\begin{equation}
	\dfrac{1}{r} = S_{\omega} (r) + L_{\omega} (r) = \dfrac{erfc(\omega r)}{r} + \dfrac{erf(\omega r)}{r}
\end{equation}
this $\omega$ parameter is semiempirical. When with use HSE03 and HSE06 functionals we set $\omega$ to $0.3$ and $0.2$ respectively.


Hybrid functionals will give us the better approximation for energy functional in the the current computational studies, but their computational cost implemenation is high as we can see in Fig. \ref{fig_2.1}.

\begin{figure}[H]
	\includegraphics[width=14cm]{Figures/jacob_lader.jpg}
	\centering
	\caption{Jacob's Ladder of exchange-correlation functionals, as proposed by J.P. Perdew, illustrates the progression from the simplest approximations (Local Density Approximation, LDA) to more sophisticated and accurate functionals (Generalized Random Phase Approximations), ultimately reaching the "Heaven of Chemical Accuracy." The hierarchy is structured based on both the complexity of the functional and the accuracy of the results. Each rung represents an enhancement in accuracy by incorporating more detailed dependencies on the electron density \(n(\mathbf{r})\) and its derivatives, such as the gradient \( \nabla n(\mathbf{r}) \), the Laplacian \( \nabla^2 n(\mathbf{r}) \), or the kinetic energy density \( \tau \). The GGA functionals, such as PBE and PBEsol, discussed earlier in this work, occupy the second rung, offering a balance between simplicity and accuracy. Hybrid GGAs (e.g., HSE06) and meta-GGAs (e.g., SCAN) ascend higher on the ladder, achieving greater chemical accuracy through the inclusion of additional terms.}
	
	\label{fig_2.1}
\end{figure}


\section{DFT and Magnetism}
\label{section.DFT_magnetism}
In materials science, particularly when studying magnetic materials, Density Functional Theory (DFT) provides a powerful framework for understanding electronic structures. This is crucial for applications ranging from elucidating magnetism to designing high-energy-density permanent magnets and developing data storage technologies.

To explore the fundamental properties of electrons, we need to consider both electron density and spin density. Previously, we introduced electron density to identify an appropriate exchange-correlation functional. However, as Dirac proposed, an electron with velocity \( v \) and orbital angular momentum \( \mathbf{L} \) generates and interacts with a magnetic field. This intrinsic property, known as 'spin,' must be explicitly addressed.

Thus, we expand our discussion to include spin density. This requires redefining the many-body wavefunction \( \mathbf{\Psi} \) as a 4-spinor:

\begin{equation}
	| \mathbf{\Psi} \rangle = \begin{pmatrix}
		|\psi_{\uparrow} \rangle \\
		| \psi_{\downarrow} \rangle
	\end{pmatrix}
\end{equation}

Consequently, we can express the electronic and spin densities as 2-spinors, dependent on the position \( \mathbf{r} \):

\begin{align}
	n (\mathbf{r}) &= \sum_{i} \mathbf{\Psi}_{i}^{\textsuperscript{\textdagger}} (\mathbf{r}) \mathbf{\Psi}_{i} (\mathbf{r}) \\
	\mathbf{s} (\mathbf{r}) &= \sum_{i} \mathbf{\Psi}_{i}^{\textsuperscript{\textdagger}} (\mathbf{r}) \mathbf{S} (\mathbf{r}) \mathbf{\Psi}_{i} (\mathbf{r})
\end{align}

where \( \mathbf{S} = \frac{\hbar}{2} \mathbf{\sigma} \) represents the spin operator, with \( \mathbf{\sigma} \) denoting the Pauli matrices:

\begin{equation}
	\sigma_{x} = \begin{pmatrix}
		0 & 1 \\
		1 & 0
	\end{pmatrix}, \quad
	\sigma_{y} = \begin{pmatrix}
		0 & -i \\
		i & 0
	\end{pmatrix}, \quad
	\sigma_{z} = \begin{pmatrix}
		1 & 0 \\
		0 & -1
	\end{pmatrix}
\end{equation}

Thus, electron and spin densities are defined as:

\begin{align}
	n(\mathbf{r}) &= \sum_{\alpha} n_{\alpha \alpha'} (\mathbf{r}) \\
	\mathbf{s} (\mathbf{r}) &= \frac{\hbar}{2} \sum_{\alpha \beta} n_{\alpha \beta} (\mathbf{r}) \mathbf{\sigma}_{\alpha \beta}
\end{align}

We can then define a functional \( G[n_{\alpha \beta}] \) that is minimized at the ground state density matrix \( n_{\alpha \beta}^{0} (\mathbf{r}) \):

\begin{equation}
	\frac{\delta G[n_{\alpha \beta}]}{\delta n_{\alpha \beta}} \Bigg|_{n_{\alpha \beta}^{0}} = 0
\end{equation}

This leads to the Kohn-Sham equations for spin-DFT:

\begin{equation}
	\left[-\frac{1}{2} \nabla^{2} + V_{n}(\mathbf{r}) + V_{H}(\mathbf{r}) \right] \psi_{i}(\mathbf{r};\alpha) + \sum_{\beta} v_{\alpha \beta}^{xc} (\mathbf{r}) \psi_{i} (\mathbf{r}; \beta) = \varepsilon_{i} \psi_{i}(\mathbf{r};\alpha)
\end{equation}

where the exchange-correlation potential \( v_{\alpha \beta} (\mathbf{r}) \) is given by:

\begin{equation}
	v_{\alpha \beta} (\mathbf{r}) = \frac{\delta E_{xc}}{\delta n_{\alpha \beta}} \Bigg|_{n_{\alpha \beta} (\mathbf{r})}
\end{equation}

Rearranging terms, we define:

\begin{align*}
	V_{xc} &= \frac{v_{\uparrow \uparrow}^{xc} + v_{\downarrow \downarrow}^{xc}}{2} \\
	B_{x}^{xc} &= \frac{v_{\uparrow \downarrow}^{xc} + v_{\downarrow \uparrow}^{xc}}{2 \mu_{B}} \\
	B_{y}^{xc} &= i \frac{v_{\uparrow \downarrow}^{xc} - v_{\downarrow \uparrow}^{xc}}{2 \mu_{B}} \\
	B_{z}^{xc} &= \frac{v_{\uparrow \uparrow}^{xc} - v_{\downarrow \downarrow}^{xc}}{2 \mu_{B}}
\end{align*}

Thus, the exchange-correlation matrix is redefined as:

\begin{equation}
	v_{\alpha \beta} (\mathbf{r}) = V_{xc} (\mathbf{r}) \mathbf{1} + \mu_{B} \mathbf{\sigma} \cdot \mathbf{B}_{xc}(\mathbf{r})
\end{equation}

Finally, the Schrödinger equation incorporating spin-DFT is:

\begin{equation}
	\left[-\frac{1}{2} \nabla^{2} + V_{n}(\mathbf{r}) + V_{H}(\mathbf{r}) + V_{xc}(\mathbf{r}) + \mu_{B} \mathbf{\sigma} \cdot \mathbf{B}_{xc}(\mathbf{r})\right] \mathbf{\Psi}_{i}(\mathbf{r}) = \varepsilon_{i} \mathbf{\Psi}_{i}(\mathbf{r})
\end{equation}


It is important to consider the different magnetic configurations a system can exhibit. There are three possible configurations: ferromagnetism, antiferromagnetism, and paramagnetism. See Fig. \ref{fig:magnetictypes}.

\begin{figure}[H]
	\centering
	\includegraphics[width=12cm]{Figures/magnetic_confgurations.png}
	\caption{Types of magnetism. ($\mathbf{a}$) shows a ferromagnetic configuration where all spins are aligned parallel. ($\mathbf{b}$) shows an antiferromagnetic configuration where spins are aligned antiparallel in a magnetic order. ($\mathbf{c}$) shows a paramagnetic configuration where the spins of electrons are randomly oriented without a preferred direction.}
	\label{fig:magnetictypes}
\end{figure}

\section{Computational implementation of DFT: the Vienna ab initio Simulation
	Package (VASP)}
\label{section.VASP}

The present work  is based on computational studies perfomed on VASP package.  This package   employs  DFT methodology (it coudl be also perfomed calculations based on the GW method and dynamical electronic correlations) to perform  ab initio calculations; widely used for a lot of currently research groups  of a widely fields of investigations such as quantum  theory of materials, solid state physics, materials sciences, etc.

VASP provides several fuunctionals , that are also bases on pseudopotentials to would be used based on system under  investigation such as GGA, LDA, hybrids functionals, metaGGA functionals, etc.;  in a way that we can replicate the electronic structure of a system under studied. 

I would be explained some  important aspects to consider within VASP framework .

\subsection{Pseudopotentials}


In exploring the wavefunctions that describe a range of atoms, we encounter a crucial question: how can we effectively manage the rapid oscillations of electron wavefunctions near the nucleus, which arise from the strong Coulomb potential? 

To begin, we must consider the frozen-core approximation, which treats valence and core electrons separately. This approximation assumes that the nuclei remain immobile by effectively freezing the core electrons in their ground state, thus enabling us to focus on the valence electrons and significantly reduce computational costs. However, it is important to note that if core electrons are not treated appropriately, valence electrons may not be screened adequately. This screening effect is particularly critical in complex systems.  


To mitigate these issues, Hamms Hemman introduced the concept of pseudopotentials in 1934 \supercite{hellmann1935new}. This method replaces the oscillatory behavior of the Coulomb potential near the nucleus with a pseudopotential that accurately captures scattering effects within a specified energy range \supercite{martin2020electronic}. By effectively "freezing" the core region, this approach facilitates the study of low-energy states without the complications of strong core interactions. 

Pseudopotentials effectively construct a repulsive potential that gives rise to pseudo-valence wavefunctions \( |\tilde{\psi}_v\rangle \). These pseudo-valence wavefunctions are designed to reproduce the true valence wavefunctions \( |\psi_v\rangle \), ensuring they remain orthogonal to the core wavefunctions \( |\psi_c\rangle \):  

\begin{equation}  
	|\tilde{\psi}_v\rangle = |\psi_v\rangle + \sum_{c} |\psi_c\rangle \langle \psi_c | \tilde{\psi}_v\rangle
   \label{eq:2.77}	
\end{equation}  

Furthermore, these pseudo wavefunctions \( |\tilde{\psi}_v\rangle \) must satisfy the effective single-particle Schrödinger equation:  

\begin{equation}  
	H_{eff} | \psi_i \rangle = \varepsilon_i | \psi_i \rangle \quad \text{for } i = c, v.  
\end{equation}  

This leads us to the equation:  

\begin{align}  
	H_{eff} |\tilde{\psi}_v\rangle &= \varepsilon_v |\psi_v\rangle + \sum_{c} \varepsilon_c |\psi_c\rangle \langle \psi_c | \tilde{\psi}_v\rangle \\   
	&= \varepsilon_v |\psi_v\rangle + \sum_{c} \left( \varepsilon_c - \varepsilon_v \right) |\psi_c\rangle \langle \psi_c | \tilde{\psi}_v\rangle.  
\end{align}  

Arranging this yields:  

\begin{equation}  
	\left[ H_{eff} + \sum_{c} \left( \varepsilon_c - \varepsilon_v \right) |\psi_c\rangle \langle \psi_c | \right] |\tilde{\psi}_v\rangle = \varepsilon_v |\tilde{\psi}_v\rangle.  
	\label{eq:2.81}
\end{equation}  

As a result, we obtain the effective Hamiltonian of the pseudo-valence states given by:  

\begin{equation}  
	H_{ps} = H_{eff} + \sum_{c} \left( \varepsilon_c - \varepsilon_v \right) |\psi_c\rangle \langle \psi_c |.  
\end{equation}  

Thus, we can express the pseudopotential as:  

\begin{equation}  
	v_{ps} = v_{eff} + \sum_{c} \left( \varepsilon_c - \varepsilon_v \right) |\psi_c\rangle \langle \psi_c |.  
\end{equation}  

It is noteworthy that the pseudo-valence wavefunction, $|\psi_{ps} \rangle =|\tilde{\psi}_v\rangle $, associated with Eq. \ref{eq:2.81} has the same single-particle energy as the true valence wavefunction. However the pseudo wavefunction  is not normalized in contrast to the normalized true wavefunction \( |\psi_v\rangle \). This can be demonstrated by normalizing both sides of Eq. \ref{eq:2.77}, revealing that the discrepancy in normalization is on the order of approximately 0.1 \supercite{Gross2003}:  

\begin{equation}  
	1 - \langle \psi_{ps} | \psi_{ps} \rangle = \sum_{i} |\langle \psi_{c} | \psi_{ps} \rangle|^{2}.  
\end{equation}  

While this approach improves the representation of the nodal behavior of the valence wavefunction near the nucleus by employing a smoother wavefunction, it may also introduce certain inconveniences. To address these, several pseudopotentials have been developed to ensure correct behavior of the true valence wavefunction. According to Richard Martin\supercite{martin2020electronic}, there are two key factors to consider when choosing a pseudopotential:  

\begin{itemize}  
	\item On one hand, when the goal is to accurately replicate the true valence wavefunction \( \psi_{c} \), a smaller cutoff radius \( r_{c} \) (defined as the distance beyond which the pseudopotential effectively vanishes) is preferred. This approach typically results in the use of hard pseudopotentials, which provide a more precise description of the electron interaction in the vicinity of the nucleus. Hard pseudopotentials are particularly effective for capturing the strong interactions present in systems where the core states play a significant role.  
	
	\item On the other hand, to optimize computational efficiency and reduce the complexity of calculations, a larger cutoff radius is often selected. This choice leads to the use of soft pseudopotentials, which allow for a smoother representation of the wavefunction and thereby simplify the mathematical treatment. Soft pseudopotentials can efficiently capture the essential physics of the system while requiring the use of fewer basis functions, significantly lowering the overall computational costs without sacrificing accuracy in many cases.  
\end{itemize}

\subsection{Projector Augmeted Wave  method (PAW) in  VASP}





\subsubsection{General Overview}  
The Projector Augmented Wave (PAW) method, implemented in the Vienna Ab initio Simulation Package (VASP), provides an accurate description of valence wave functions using a refined approach to pseudopotentials. PAW is based on the ultrasoft pseudopotential technique, which utilizes an auxiliary function surrounding each ionic core to enhance computational efficiency. Originally proposed by Blöchl, this method was subsequently generalized for magnetic systems in a collinear framework by Hobbs, Kress, and Hafner.  

This section highlights the essential concepts of the PAW method.  

\subsubsection{Key Concepts}  

\begin{itemize}  
	
	\item \textbf{Brillouin Zone Integration}  
	
	To describe a crystal system, it is essential to introduce the concept of the unit cell, which serves as the fundamental building block of the crystal lattice, characterized by a Bravais lattice—a periodic arrangement of lattice points. Each lattice point can be represented by lattice vectors $\mathbf{R}$:  
	
	\begin{equation}  
		\mathbf{R} = n_1 \mathbf{a_1} + n_2 \mathbf{a_2} + n_3 \mathbf{a_3},  
	\end{equation}  
	
	where $n_1, n_2, n_3$ are integers and $\mathbf{a_i}$ are the primitive vectors defining the lattice. Modeling a unit cell suffices to represent the entire crystal.  
	
	To analyze electrons within the unit cell, we consider an electron subjected to a periodic potential $U(\mathbf{r})$ that satisfies the condition:  
	
	\begin{equation}  
		U(\mathbf{r} + \mathbf{R}) = U(\mathbf{r}),  
	\end{equation}  
	
	where $\mathbf{R}$ is a lattice vector. This leads to Bloch's theorem, which states that the eigenstates $\psi$ of the one-electron Hamiltonian $\hat{H} = -\nabla^2 + U(r)$ can be expressed as:  
	
	\begin{equation}  
		\psi_{n\mathbf{k}}(\mathbf{r}) = e^{i\mathbf{k} \cdot \mathbf{r}} u_{n\mathbf{k}}(\mathbf{r}),  
		\label{eq:2.87}  
	\end{equation}  
	
	where $\mathbf{k}$ is the wave vector defined in reciprocal space, and $u_{n\mathbf{k}}(\mathbf{r})$ is a periodic function of the Bravais lattice. It is crucial to account for the reciprocal lattice vector $\mathbf{G}$ to ensure that the wavevector $\mathbf{k}$ lies within the first Brillouin Zone (BZ), considering periodic boundary conditions:  
	
	\begin{equation}  
		\mathbf{k'} = \mathbf{k}+\mathbf{G} \quad \text{with} \quad \mathbf{G}= m_{1}\mathbf{b_1}+m_{2}\mathbf{b_2}+m_{3}\mathbf{b_3}  
	\end{equation}  
	
	This formulation is essential for solving the Schrödinger equation and analyzing electron behavior in periodic potentials. By substituting the single-particle electronic wavefunction into the Kohn-Sham equations and normalizing, we obtain:  
	
	\begin{equation}  
		\int_{uc} | u_{n \mathbf{k}}(\mathbf{r})|^{2} d \mathbf{r} = 1,  
		\label{eq:2.88}  
	\end{equation}  
	
	indicating that while the wavefunction $\psi_{n\mathbf{k}}$ is non-periodic, we must solve the Schrödinger equation for $u_{n\mathbf{k}}$ on a discrete grid in reciprocal space and apply appropriate boundary conditions to construct the electron density $n(\mathbf{r})$.  

\
\item \textbf{k-point sampling}

From Eq. \ref{eq:2.88}, we observe that the electronic density depends on the band index \(n\) and the \(\mathbf{k}\)-point in the reciprocal space within the Brillouin zone. Therefore, the relationoship between the  eigenvalues and wavefunctions that arise from periodic boundary conditions relate to the \(\mathbf{k}\)-point as follows:

\begin{equation}
	\epsilon_{\lambda} = \epsilon_{n \mathbf{k}} \quad \text{and} \quad \psi_{\lambda} = \psi_{n \mathbf{k}}.
\end{equation}

An appropriate choice of \(\mathbf{k}\)-points is essential for accurately representing the electron density for occupied states \(n \mathbf{k}\) as indicated in Eq. \ref{eq:2.88}. For larger unit cells, fewer \(\mathbf{k}\)-points are necessary:

\begin{equation}
	n(\mathbf{r}) = 2 \sum_{n}^{\text{occ}} |\psi_{n \mathbf{k}}(\mathbf{r})|^{2}.
\end{equation}

In the context of the Vienna Ab initio Simulation Package (VASP), two primary \(\mathbf{k}\)-point sampling methods are employed: the Monkhorst-Pack scheme and \(\Gamma\)-centered meshes.

The Monkhorst-Pack scheme generates a uniform grid of \(\mathbf{k}\)-points that are symmetrically distributed in the Brillouin zone. This method is advantageous for systems with high symmetry, as it allows for efficient integration over the Brillouin zone while ensuring that all relevant states are adequately sampled.

According to VASP documentation, the \(\mathbf{k}\)-points that sample the Brillouin zone for the Monkhorst-Pack scheme are given by:

\begin{equation}
	\mathbf{k} = \sum_{i=1}^{3} \frac{n_i + s_i + \frac{1 - N_i}{2}}{N_i} \mathbf{b}_i \quad \forall n_i \in [0, N_i[
\end{equation}

where

\begin{equation}
	\begin{aligned}
		n_i &: \text{ indices representing the subdivisions along each direction,} \\
		s_i &: \text{ optional shift in terms of subdivisions,} \\
		N_i &: \text{ total number of subdivisions along each direction,} \\
		\mathbf{b}_i &: \text{ reciprocal lattice vectors.}
	\end{aligned}
\end{equation}

On the other hand, \(\Gamma\)-centered meshes utilize \(\Gamma\) (the center of the Brillouin zone) as a reference point. This approach is often preferred for calculations involving metallic crystals, where the presence of electronic states near the Fermi level can substantially affect the results. The \(\Gamma\)-centered method helps capture these states more effectively, providing a denser sampling near the zone center.

According to the documentation, the \(\mathbf{k}\)-points sample in the Brillouin zone are given by:

\begin{equation}
	\mathbf{k} = \sum_{i=1}^{3} \frac{n_i + s_i}{N_i} \mathbf{b}_i \quad \forall n_i \in [0, N_i[
\end{equation}

Both methods are crucial in achieving accurate electronic structure calculations and ensuring convergence in properties derived from these calculations, such as total energy, forces, and electron densities. Generally, the \(\mathbf{k}\)-point mesh is given by a mesh in the form of:

\begin{equation}
	N_x \times N_y \times N_z
\end{equation}

Generally, such subdivisions are the same \(N_x = N_y = N_z\). However, for monolayers \(N_x = N_y, N_z = 1\).

It is important to mention that choosing the \(\mathbf{k}\)-point scheme generally yields the same accuracy. However, it is advisable for a hexagonal crystalline lattice to choose a \(\Gamma\)-centered scheme, as discussed by Chadi and Cohen \cite{chadi1973special}, where an odd-grid is recommended due to space group symmetry considerations.

\item \textbf{Plane Wave Expansion}  

In the Projector-Augmented Wave (PAW) method, wavefunctions are described using plane waves due to their computational efficiency and completeness in representing periodic systems. From Bloch's theorem in Equation \ref{eq:2.87}, we recognize that $u_{n \mathbf{k}}$ is periodic, and, following the analysis provided by Kantorovich \supercite{kantorovich2004}, this periodic function can be expanded in direct space. Since $\psi_{n \mathbf{k}}$ is generally not periodic, we can expand it in reciprocal space using Fourier series, leading to the following expression:  

\begin{equation}  
	\psi_{n \mathbf{k}}(\mathbf{r}) = e^{i \mathbf{k} \cdot \mathbf{r}} \frac{1}{\sqrt{\Omega}} \sum_{\mathbf{G}} e^{i \mathbf{G} \cdot \mathbf{r}} C_{n \mathbf{k}}(\mathbf{G})  
\end{equation}  

where $ C_{n \mathbf{k}}(\mathbf{G}) $ are the corresponding Fourier coefficients and \


\item \textbf{Cut-off energy} \label{cutoff-energy}

Now that the basic concepts are introduced, let us delve deeper. As we remember from the pseudopotential section, the goal of the pseudo-valence wave function is to treat its nodal behavior. In this sense, plane waves with larger lattice vectors \(\mathbf{G}\) are required to account for the aggressive valence wave functions near the core. Practically, this requires significant computational cost. To capture the main behavior of quantum states of the pseudo-valence wave function \(\tilde{\psi}_v\) and avoid counting oscillations at short distances, it is advisable to define a cut-off radius that describes the \(G_{max}\) needed to accurately describe the valence spin-orbitals \(\psi_v\).

\begin{equation}
	|\mathbf{G}| \leq G_{max}
\end{equation}

Using plane waves, we must follow the convergence criterion:

\begin{equation}
	|\mathbf{G} + \mathbf{k}| < G_{max}
\end{equation}

We aim to choose the associated cut-off energy adequately \(E_{cut} = \frac{\hbar^2}{2m} G_{max}^2\).

In VASP, the cut-off energy is explicitly accounted for based on the atom and its orbital states. However, for systems with different atomic species, a convergence criterion given by the relationship between the cut-off energy and the total energy of a given system is needed:

\begin{equation}
	\Delta E < 1 \, \text{meV/atom}
\end{equation}

to obtain a good description of electronic properties.




\item \textbf{Two-Dimensional Equation of State} \label{2D.eqs}

In ab initio calculations, such as those performed using VASP, determining accurate lattice parameters is crucial. This determination provides a proper description of band gaps, magnetic moments, and is strongly correlated with phonon calculations. The Birch equation of state is commonly used for bulk systems; however, for computational studies of two-dimensional systems, a different equation of state is necessary to relate the system's area with its corresponding total energy. The equation derived from Andrew's paper \supercite{andrew2012} is employed for this purpose:

\begin{equation}  
	E(A) = E_0 + 4 A_0 \gamma_0 \left\{ \frac{1}{2} \epsilon^2 + \frac{1}{6} (5 - \gamma_0') \epsilon^3  + \frac{1}{6}\left[ (1 - \gamma_0') (8 - \gamma_0')+ \gamma_0 \gamma_0''+18 \right] \epsilon^4 \right\}  
\end{equation}  

Here, $A_0$, $\gamma_0$, $\gamma_0'$, and $\gamma_0''$ are the equilibrium values for the unit-cell area, layer modulus, the derivative of the force per unit length, and the second derivative of the layer modulus at $\mathcal{F}=0$ (two-dimensional force per unit length), respectively. The strain $\epsilon$ is defined as the equibiaxial Eulerian strain:

\begin{equation}  
	\epsilon = \frac{1}{2} \left[ 1 - \frac{A_0}{A} \right].  
\end{equation}  


\end{itemize}
\subsubsection{Projector Augmented Wave (PAW) Method}  
With the foundational concepts introduced, we will now delve into the Projector Augmented Wave (PAW) method, which is extensively utilized in VASP for its ability to reduce computational costs while ensuring a numerical treatment compatible with pseudopotentials.  

The primary objective of the PAW method is to accurately describe the true all-electron (AE) wavefunction from the pseudo wavefunction. A generalized form of this relationship can be expressed as follows:  

\begin{equation}  
	\Psi = T \tilde{\Psi}  
	\label{eq:2.101}  
\end{equation}  

Here, \(T\) is defined as a transformation operator representing the connection between the true and pseudo wavefunctions. The significance of the PAW method is underscored in the following aspects:  

\begin{itemize}  
	\item It facilitates a detailed description of the nodal structure of the pseudo valence wavefunction within each atomic region.  
	\item It introduces the concept of the "Augmentation Sphere," which connects the pseudo wavefunction inside the augmentation region to that outside, delimited by the cutoff radius \(r_c\). Within this sphere, the pseudo wavefunction adheres to Equation \ref{eq:2.101}, while outside, we utilize \(\Psi = \tilde{\Psi}\).  
\end{itemize}  

Given that \(T\) exhibits distinct behaviors inside and outside the augmentation sphere, it is beneficial to define it as:  

\begin{equation}  
	T = \mathbbm{1} + \sum_{R} T_{R}  
	\label{eq:2.102}  
\end{equation}  

In this expression, \(\mathbbm{1}\) denotes the identity operator, while \(T_{R}\) represents orbital-based modifications.  

To elucidate these orbital-based modifications, we identify three critical components:  

\begin{itemize}  
	\item All-electron partial waves \( |\phi_{i} \rangle \)  
	\item Pseudo partial waves \( |\tilde{\phi}_{i} \rangle \)  
	\item Projector functions \( | \tilde{p}_{i} \rangle \), which facilitate the treatment of localized atomic orbitals within the augmentation sphere. The orthonormality condition \( \langle \tilde{p}_i | \tilde{\phi}_j \rangle = \delta_{ij} \) holds for states within this region, leading to the completeness relation \( \sum_{i} | \tilde{\phi}_{i} \rangle \langle \tilde{p}_i | = \mathbbm{1} \).  
\end{itemize}  

In conformity with Bloch's theorem, we can express the pseudo valence wavefunction in terms of plane waves. To incorporate atomic orbital modifications appropriately, we represent a plane wave as a sum of spherical waves:  

\begin{equation}  
	e^{i \mathbf{k} \cdot \mathbf{r}} = 4 \pi \sum_{l=0}^{\infty} \sum_{m=-l}^{l} i^{l} j_{l}(k r) Y_{l}^{m} (\hat{k}) Y_{l}^{m*} (\hat{r}).  
\end{equation}  

This expression enables us to describe the electronic wavefunction states indexed by \(i=(R,l,m,n)\). Consequently, the all-electron wavefunction, derived from Equation \ref{eq:2.102}, can be written as:  

\begin{equation}  
	\Psi = \tilde{\Psi} + \sum_{i} \left( | \phi_i \rangle \langle \tilde{p}_i | \tilde{\Psi} \rangle - | \tilde{\phi}_i \rangle \langle \tilde{p}_i | \tilde{\Psi} \rangle \right)  
	\label{eq:2.104}  
\end{equation}  

This formulation reveals essential features of the all-electron wavefunction, which consists of three components: the first represents the pseudized version of the wavefunction, facilitating computational efficiency; the second incorporates the all-electron contributions within the augmentation region; and the third addresses the contributions of the pseudized wavefunctions within the overall wavefunction.  

Further mathematical details are outside the scope of this discussion, as they are not the primary focus of this thesis. However, it is pivotal to note that the true all-electron density can be computed based on the contributions expressed as:  

\begin{equation}  
	n(\mathbf{r}) = \tilde{n}(\mathbf{r}) + n^{1}(\mathbf{r}) - \tilde{n}^{1}(\mathbf{r})  
\end{equation}  

In this equation, \(n^{1}(\mathbf{r})\) is referred to as the "one-center" electronic density, accounting for the total contributions from all valence atomic states within the augmentation region.  

Thus, we establish a clear advancement over conventional pseudopotentials by incorporating a dependency on three distinct constituents of the electronic density. As previously discussed, we can evaluate the exchange-correlation energy based on this electronic density framework.  

Substantial contributions from Kresse and Joubert have further enhanced the PAW method by integrating it with well-established  plane wave implementations \supercite{kresse1999}, shifting the focus away from purely partial wave treatments. They reformulated the pseudo exchange-correlation treatment into a plane wave context by considering the vital contributions encapsulated in Equation \ref{eq:2.104}. Additionally, they introduced a valence compensation charge density \(\hat{n}\) to correct the charge pseudodensity in exchange-correlation energy calculations:  

VASP offers functionality to construct pseudopotentials utilizing the PAW method; however, availability of the pseudopotential generator package may vary.  
\begin{equation}  
	E_{K \, xc} = E_{xc}[\tilde{n} + \tilde{n}_c + \hat{n}] + \sum_{a} \left( E_{xc}^{a}[\tilde{n}^{a} + \hat{n}_c^a] - E_{xc}^{a}[\tilde{n}^{a} + \tilde{n}_c^a + \hat{n}^a] \right).  
\end{equation}  


\subsubsection{\texorpdfstring{PAW and LDA$+$U}{PAW and LDA+U}} \label{pawldau}


In this section, we discuss the implementation of the Projector Augmented Wave (PAW) method within the LDA+U framework. It is important to note that the electronic density defined in the PAW formalism does not account for spin-charge density. To address this limitation, Bengone et al. \supercite{bengone2000} redefined the electron charge density to incorporate spin effects, leading to the following formulation:  

\begin{equation}  
	n_{m,m'}^{\tau, \sigma} = \sum_{n, \mathbf{k}} f_{n, \mathbf{k}}^{\sigma} \langle \tilde{\Psi}_{n}^{\mathbf{k}, \sigma} | \tilde{P}_{m, m'}^{\tau} | \tilde{\Psi}_{n}^{\mathbf{k}, \sigma} \rangle  
\end{equation}  

where the variables are defined as follows:  

\begin{flalign*}  
	& \tau \equiv \text{atomic site}, \\
	& \sigma \equiv \text{spin}, \\
	& m, m' \equiv \text{magnetic quantum numbers for an } \ell \text{ (defining the matrix)}, \\
	& n \equiv \text{band index}, \\
	& \mathbf{k} \equiv \text{given k-point}, \\
	& f \equiv \text{Fermi distribution}, \\
	& \Psi \equiv \text{All-Electron (AE) wavefunction}, \\
	& P \equiv \text{projection operator}.  
\end{flalign*}  

This formulation focuses on the occupation matrix for orbitals on atom \(\ell\), where \(m = m' = m_j\).  

To study highly localized orbitals, such as \(d\) orbitals, we assume that within the augmentation region, the contributions from the basis functions approach unity:  

\begin{equation}  
	\sum_{i} | \tilde{\phi}_i \rangle \langle \tilde{p}_i | \approx 1.  
\end{equation}  

Thus, we can express the spin-dependent charge density as:  

\begin{equation}  
	n_{m,m'}^{\tau, \sigma} = \sum_{n, \mathbf{k}}^{\sigma} f_{n, \mathbf{k}}^{\sigma} \sum_{ij} \langle \tilde{\Psi}_{n}^{\mathbf{k}, \sigma} | \tilde{p}_i \rangle \langle \tilde{p}_i | \tilde{\Psi}_{n}^{\mathbf{k}, \sigma} \rangle.  
\end{equation}  

Here, the indices \((i,j) = (l,m,n)\) are related to angular momentum, magnetic angular momentum, and plane wave indices. This distinction is crucial when treating atoms with orbitals \(l_{ij}\) that share the same magnetic angular momentum. We can derive a simplified version of the previous equation:  

\begin{equation}  
	n_{m, m'}^{\tau,\sigma} = \sum_{i,j} \rho_{ij}^{\sigma} \langle \tilde{\phi}_{n_i} | \tilde{\phi}_{n_j} \rangle,  
\end{equation}  

where \(\rho_{i,j}\) represents the spin density for both spin channels. This formulation introduces the Hubbard \(U\) term, which corrects the behavior of highly localized orbitals and is expressed as:  

\begin{equation}  
	U_{\text{eff}} = U - J.  
\end{equation}  

Dudarev et al. \supercite{Dudarev1998} further developed these implications to study transition metals with strongly correlated \(d\) electrons. Their approach emphasizes the importance of incorporating both Coulomb repulsion (\(U\)) and exchange interaction (\(J\)), allowing for a more accurate description of the electronic structure in such correlated systems. 


\subsection{Special Quasirandom Structures} \label{sqs}

VASP implements several approaches to accurately describe the electronic behavior of various systems. For example, in Section \ref{pawldau}, we discussed the application of Hubbard U corrections to account for highly correlated orbitals. In this section, we will focus on the study of random alloys through the "Special Quasirandom Structures" (SQS) method \supercite{wei1990electronic,zunger1990special}. VASP employs a two-step method for SQS, which is implemented using the Alloy Theoretic Automated Toolkit (ATAT) software package. Below, we describe key concepts of the SQS method and its application in VASP.

Consider a lattice of \(N\) atoms representing a binary random alloy \(A_{1-x}B_{x}\), where \(x\) denotes the desired composition related to the random occupation of lattice sites by \(A\) or \(B\) atoms. To model this system, we define a set \(\Lambda = \{1, 2, \dots, N\}\) of lattice points, where each site \(i\) is characterized by a configuration \(\sigma_k \in \Lambda\). Using the Ising model, we assign each configuration \(\sigma_k \in \{-1, 1\}\): \(+1\) if site \(k\) is occupied by an \(A\) atom, and \(-1\) if occupied by a \(B\) atom. However, evaluating the expectation value of any physical property from the Ising model Hamiltonian,

\begin{equation}
	\langle f(\sigma) \rangle = \sum_{\sigma}^{2^N} \rho(\sigma) f(\sigma)
	\label{eq:2.113}
\end{equation}

involves \(2^N\) terms, leading to a significant computational cost. To address this issue, the first step of the SQS method reduces the computational burden by considering clusters. A cluster is defined as a set of lattice sites (e.g., pairs, triples, etc.), and these clusters can be represented by "figures," which are determined by:
\begin{itemize}
	\item The number of endpoints, \(k\),
	\item The order, \(m\), of nearest neighbors (NN),
	\item The position \(l\) of the figure in the lattice system.
\end{itemize}

Using the Ising model, we define a cluster function \(\Gamma_\alpha(\sigma)\) for a given configuration \(\sigma_k\) as the product of spin variables \(\hat{\mathbf{S}}_k = \mathbf{\sigma} = \{\sigma_k\}_{k \in \Lambda}\) corresponding to that figure:

\begin{equation}
	\Gamma_\alpha(\sigma) = \prod_f (l, \sigma)
\end{equation}

This leads to the averaged lattice function over all positions of figures in the lattice:

\begin{equation}
	\overline{\Gamma}_f(\sigma) = \frac{1}{N D_f} \sum_l \Gamma_f(l, \sigma)
	\label{eq:2.115}
\end{equation}

where \(D_f\) accounts for the fact that a site in a cluster can contribute to multiple configurations. This concept introduces a key parameter, the "effective cluster property" \(\varepsilon_f\), which allows us to express any physical property from Eq. \ref{eq:2.113} as a weighted superposition of cluster functions:

\begin{equation}
	f(\mathbf{\sigma}) = \sum_f \varepsilon_f(l) \Gamma_f(l, \sigma)
	\label{eq:2.116}
\end{equation}
where
\begin{equation}
	\varepsilon_f(l) = \frac{1}{N} \sum_\sigma f(\mathbf{\sigma}) \Gamma_f(l, \sigma)
	\label{eq:2.117}
\end{equation}

By substituting Eq. \ref{eq:2.115} into Eq. \ref{eq:2.116}, we obtain the weighted superposition of the expectation value of the average lattice function:

\begin{equation}
	\langle f \rangle = N \sum_f D_f \langle \overline{\Gamma}_f \rangle \varepsilon_f
	\label{eq:2.118}
\end{equation}

This equation reduces the computational cost by sampling over all figures of the lattice system instead of considering all configurations as in Eq. \ref{eq:2.113}. The second step of the SQS method involves considering a set of \(N_s\) periodic structures, \(\sigma = s\), and identifying a figure \(f < F\) that best mimics the random alloy \(A_{1-x}B_x\). Since figures with more than \(k = 3\) or \(k = 4\) vertices contribute less significantly to the cluster functions, we have:

\begin{equation}
	f(\sigma) = \sum_{s=1}^{N_s} \xi_s(\sigma) f(s)
\end{equation}
and
\begin{equation}
	\xi_s(\sigma) = \sum_{f=1}^{F} \left[ \overline{\Gamma}_{f}(s) \right]^{-1} \overline{\Gamma}_{f}(\sigma)
\end{equation}

where \(\xi_s\) is the weight of the \(s\)-th special configuration.

The correlation functions for a perfect random alloy \(R\) are given by:

\begin{equation}
	\overline{\Gamma}_{k,m}(R) = \langle \overline{\Gamma}_{k,m} \rangle_R = (2x-1)^{k}
	\label{eq.2.121}
\end{equation}

A good SQS structure approximates a random alloy's correlation functions until transferability is achieved with respect to a perfect random alloy \(\langle f \rangle\). This can be measured as:

\begin{equation}
	\langle f \rangle - f(s) = \sum_{k,m} D_{k,m} \left[ (2x-1)^{k} - \overline{\Gamma}_{k,m}(s) \right] \varepsilon_{k,m}
	\label{eq:2.122}
\end{equation}

where the prime \(k'\) indicates the exclusion of \(k = 0\) and \(k = 1\) vertices. Although the SQS method works well for small systems, a limitation arises when dealing with supercells containing a large number of atoms. In such cases, a greater number of clusters \(\alpha\) must be considered. This is necessary because the method must evaluate each correlation function until the transferability condition in Eq. \ref{eq:2.122} is satisfied. To overcome this limitation, the SQS method incorporates an efficient stochastic approach: the Monte Carlo algorithm \supercite{atat5}.

While I will not delve into the mathematical formulation of the Monte Carlo method for SQS, the essence of the approach, as developed by van de Walle et al., is to seek the optimal cluster correlation functions \(\Gamma_\alpha\) by introducing an objective function:

\begin{equation}
	Q = - w L + \sum_{\alpha \in A} \left| \Delta \Gamma_{\alpha'}(\sigma)\sigma \right|
	\label{eq:2.124}
\end{equation}

where:
\begin{itemize}
	\item \(w\) is a user-specified weight, fundamental for obtaining a good SQS,
	\item \(L\) is the largest distance for which \(\text{diam}(\alpha) < L\),
	\item \(\alpha'\) is an equivalent cluster to \(\alpha\),
	\item \(A\) is a chosen set of clusters \(\{ \alpha \}\).
\end{itemize}

In this way, we can obtain nearly perfect quasirandom structures for larger \(N\)-atom systems. VASP computes ab initio electronic and magnetic properties \(\{ \langle f(s) \rangle \}\) for a candidate SQS and uses the two-step method described above to best match the objective function in Eq. \ref{eq:2.124} using the Monte Carlo algorithm.

